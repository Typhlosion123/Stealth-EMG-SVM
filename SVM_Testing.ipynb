{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d28fe73",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Dense' from 'keras' (c:\\Users\\chris\\VS Code Projects\\Stealth-EMG-SVM\\.venv\\Lib\\site-packages\\keras\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dense\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dropout\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m regularizers\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'Dense' from 'keras' (c:\\Users\\chris\\VS Code Projects\\Stealth-EMG-SVM\\.venv\\Lib\\site-packages\\keras\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f191b110",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---CONFIG FRAME---#\n",
    "train_file = [\n",
    "    \"parsed_emg/subject_1/trial_11(right).csv\",\n",
    "    \"parsed_emg/subject_1/trial_3(right).csv\",\n",
    "    \"parsed_emg/subject_1/trial_5(right).csv\",\n",
    "    \"parsed_emg/subject_1/trial_7(right).csv\",\n",
    "    \"parsed_emg/subject_1/trial_9(right).csv\"\n",
    "]\n",
    "\n",
    "test_file = \"parsed_emg/subject_1/trial_1(right).csv\"\n",
    "\n",
    "label_col = 5\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "epochs = 1\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#---Data Loader---#\n",
    "def load_csv(path):\n",
    "    df = pd.read_csv(path, skiprows=1)\n",
    "    df = df.drop(columns=df.columns[0], axis=1)\n",
    "    X = df.iloc[:, 1:5].values.astype(\"float32\")\n",
    "    y = df.iloc[:, label_col].values.astype(\"int32\")\n",
    "    return X, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "58d42d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "\u001b[1m36628/36628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 635us/step - accuracy: 0.9834 - loss: 0.0801\n",
      "\u001b[1m1883/1883\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561us/step - accuracy: 0.0294 - loss: 9.6172\n",
      "\n",
      "Test loss: 7.3963 — Test accuracy: 0.2316\n"
     ]
    }
   ],
   "source": [
    "# --- Prepare the training dataset ---\n",
    "training_datasets = []\n",
    "for f in train_file:\n",
    "    X_tr, y_tr = load_csv(f)       # X_tr: shape (N, input_dim), y_tr: integer labels [0,1,2]\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X_tr, y_tr))\n",
    "    training_datasets.append(ds)\n",
    "\n",
    "# Concatenate all per-file datasets\n",
    "training_ds = training_datasets[0]\n",
    "for ds in training_datasets[1:]:\n",
    "    training_ds = training_ds.concatenate(ds)\n",
    "\n",
    "# Shuffle, batch, and prefetch\n",
    "training_ds = (\n",
    "    training_ds\n",
    "    .shuffle(buffer_size=5000)\n",
    "    .batch(batch_size)\n",
    ")\n",
    "\n",
    "# Load the test data\n",
    "X_test, y_test = load_csv(test_file)\n",
    "\n",
    "# --- Build the model ---\n",
    "num_classes = 3                # three target categories\n",
    "input_dim  = X_tr.shape[1]\n",
    "print(input_dim)    # infer number of input features\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Input(shape=(input_dim,)),\n",
    "    # Hidden layer for non-linearity\n",
    "    layers.Dense(\n",
    "        12,\n",
    "        activation=\"relu\",\n",
    "        kernel_regularizer=regularizers.l2(1e-3)\n",
    "    ),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(\n",
    "        8,\n",
    "        activation=\"relu\",\n",
    "        kernel_regularizer=regularizers.l2(1e-3)\n",
    "    ),\n",
    "    # Output layer with softmax for 3-way classification\n",
    "    layers.Dense(\n",
    "        num_classes,\n",
    "        activation=\"softmax\",\n",
    "        kernel_regularizer=regularizers.l2(1e-3)\n",
    "    ),\n",
    "])\n",
    "\n",
    "# --- Compile with sparse categorical crossentropy for integer labels ---\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    loss=\"sparse_categorical_crossentropy\",  # use this when y labels are integers\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# --- Train ---\n",
    "model.fit(training_ds, epochs=epochs)\n",
    "\n",
    "# preds = model.predict(X_test)\n",
    "# print(np.argmax(preds[100000:100010], axis=1))  # predicted classes\n",
    "# print(y_test[100000:100010])\n",
    "\n",
    "# --- Evaluate ---\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "print(f\"\\nTest loss: {test_loss:.4f} — Test accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8286b19a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
